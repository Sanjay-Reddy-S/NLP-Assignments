{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mConversations\u001b[m\u001b[m/\r\n",
      "Twitter.zip\r\n",
      "Twitter_Data.ipynb\r\n",
      "\u001b[34mTwitter_data\u001b[m\u001b[m/\r\n",
      "extract_fet_review.py\r\n",
      "hotel_review_preprocess.py\r\n",
      "\u001b[34mpan14-author-profiling-training-corpus-2014-04-16\u001b[m\u001b[m/\r\n",
      "pan14-author-profiling-training-corpus-2014-04-16.zip\r\n",
      "\u001b[34mpan16-author-profiling-training-dataset-2016-04-25\u001b[m\u001b[m/\r\n",
      "pan16-author-profiling-training-dataset-2016-04-25.zip\r\n",
      "workArea.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aditya/Google Drive/UMass/First Semester/585/Project/WorkArea/Twitter_data\n"
     ]
    }
   ],
   "source": [
    "cd Twitter_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aditya/Google Drive/UMass/First Semester/585/Project/WorkArea/Twitter_data/pan14-author-profiling-training-corpus-english-twitter-2014-04-16\n"
     ]
    }
   ],
   "source": [
    "cd pan14-author-profiling-training-corpus-english-twitter-2014-04-16/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-Processing of the Text file, as per project proposal:\n",
    "• Remove url to ‘url’, html tags, nums to ‘num’, @mentions\n",
    "• Eliminate duplicate ‘retweet’ data, which adds undue bias to our dataset.\n",
    "• Eliminate noisy tweets containing non-Latin characters.\n",
    "\n",
    "PENDING:\n",
    "• Use default svm param/ or maybe tune after finalizing features.\n",
    "• Vary C after finalizing features.\n",
    "'''\n",
    "import regex\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from __future__ import division\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import nltk\n",
    "import enchant\n",
    "\n",
    "d1=enchant.Dict(\"en_US\")\n",
    "\n",
    "def preProcessing(line):\n",
    "    #if line[0:3] == 'RT:':\n",
    "    #   return False\n",
    "    line = line.split()\n",
    "    modifiedLine = []\n",
    "    for i in range(len(line)):\n",
    "        try:\n",
    "            line[i].encode(encoding='utf-8').decode('ascii')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if 'http' in line[i].lower() or 'www.' in line[i].lower() or '.com' in line[i].lower():\n",
    "            modifiedLine.append('URL')\n",
    "        elif '@' in line[i]:\n",
    "            continue\n",
    "        else:\n",
    "            modifiedLine.append(line[i])\n",
    "            \n",
    "    line = ' '.join(modifiedLine)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def no_of_punc_line(line):\n",
    "    count=0\n",
    "    punc=['.',',','!','?',':']\n",
    "    for i in line:\n",
    "        if i in punc:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def pos_statistics(pos_text):\n",
    "    tag_fd = nltk.FreqDist(tag for (word, tag) in pos_text)\n",
    "    dict_col={'adjectives':0,'punc':1,'adverb':2,'noun':3,'verb':4,'interjection':5,'preposition':6,'article':7,'pronoun':8}\n",
    "    stats=[0]*len(dict_col)\n",
    "    for tup in tag_fd.most_common():\n",
    "        if 'RB' in tup[0]:\n",
    "            stats[dict_col['adverb']]+=tup[1]\n",
    "        elif 'NN' in tup[0]:\n",
    "            stats[dict_col['noun']]+=tup[1]\n",
    "        elif '.' in tup[0]:\n",
    "            stats[dict_col['punc']]+=tup[1]\n",
    "        elif 'JJ' in tup[0]:\n",
    "            stats[dict_col['adjectives']]+=tup[1]\n",
    "        elif 'VB' in tup[0]:\n",
    "            stats[dict_col['verb']]+=tup[1]\n",
    "        elif 'UH' in tup[0]:\n",
    "            stats[dict_col['interjection']]+=tup[1]\n",
    "        elif 'IN' in tup[0]:\n",
    "            stats[dict_col['preposition']]+=tup[1]\n",
    "        elif 'PRP' in tup[0] or 'WP' in tup[0]:\n",
    "            stats[dict_col['pronoun']]+=tup[1]\n",
    "        elif 'DT' in tup[0]:\n",
    "            stats[dict_col['article']]+=tup[1]\n",
    "    return stats\n",
    "\n",
    "#fet_names=['Total Words']\n",
    "capitals = string.ascii_uppercase\n",
    "\n",
    "def f_measure(pos_stats):\n",
    "\tdict_col={'adjectives':0,'punc':1,'adverb':2,'noun':3,'verb':4,'interjection':5,'preposition':6,'article':7,'pronoun':8}\n",
    "\tnouns=pos_stats[dict_col['noun']]\n",
    "\tadjectives=pos_stats[dict_col['adjectives']]\n",
    "\tprep=pos_stats[dict_col['preposition']]\n",
    "\tarticle=pos_stats[dict_col['article']]\n",
    "\tpro=pos_stats[dict_col['pronoun']]\n",
    "\tverb=pos_stats[dict_col['verb']]\n",
    "\tadv=pos_stats[dict_col['adverb']]\n",
    "\tinter=pos_stats[dict_col['interjection']]\n",
    "\treturn 0.5*((nouns+adjectives+prep+article)-(pro+verb+adv+inter)+100)\n",
    "\n",
    "def count_wrong(text):\n",
    "\tcount=0\n",
    "\tfor word in text:\n",
    "\t\tif d1.check(word)==False:\n",
    "\t\t\tcount+=1\n",
    "\treturn count\n",
    "\n",
    "## More features:\n",
    "\n",
    "def countHashTags(line):\n",
    "    p = re.compile('\\s#[a-zA-Z0-9]')\n",
    "    return len(p.findall(line))/len(line.split())\n",
    "\n",
    "def startsCapital(line):\n",
    "    if line[0] in capitals:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def capitalized(text):\n",
    "    count = 0\n",
    "    for word in text:\n",
    "        if word[0] in capitals:\n",
    "            try:\n",
    "                if word[1] not in capitals:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    continue\n",
    "            except:\n",
    "                count += 1\n",
    "    return count/len(text)\n",
    "\n",
    "def endsWithPeriod(line):\n",
    "    line = line.split()\n",
    "    count = 0\n",
    "    for word in line:\n",
    "        if word.endswith('.'):\n",
    "            count += 1\n",
    "    return (count/len(line))\n",
    "\n",
    "def totalCapitals(text):\n",
    "    count = 0\n",
    "    for word in text:\n",
    "        if set(word).issubset(set(capitals)):\n",
    "            count += 1\n",
    "    return count/len(text)\n",
    "\n",
    "def perc_count_wrong(text):\n",
    "\tcount=0\n",
    "\tfor word in text:\n",
    "\t\tif d1.check(word)==False:\n",
    "\t\t\tcount+=1\n",
    "\treturn count/ len(text)\n",
    "\n",
    "def perc_of_punc_line(line):\n",
    "    p = re.compile('[[a-zA-Z][\\.!?]\\s?$|[a-zA-Z][,:][\\sa-zA-Z]')\n",
    "    count = len(p.findall(line))\n",
    "    return count/len(line)\n",
    "\n",
    "def avg_word_len(text):\n",
    "    chars = 0\n",
    "    for word in text:\n",
    "        chars += len(word)\n",
    "    return chars/len(text)\n",
    "\n",
    "##############################################################################################\n",
    "fet_names=['Total Chars','Total Words','Incorrect Words']#'POS_Ones(Variable)'\n",
    "\n",
    "def words_to_fet():\n",
    "    file_counter=0\n",
    "    fp1=open('text.txt','r')\n",
    "    fp3_a=open('age.txt','r')\n",
    "    fp4_a=open('gender.txt','r')\n",
    "    fp2=open('features3.txt','w')\n",
    "    fp3=open('age_new.txt','w')\n",
    "    fp4=open('gender_new.txt','w')\n",
    "    var_count=0\n",
    "    \n",
    "    age=[]\n",
    "    gender=[]\n",
    "    for line in fp3_a:\n",
    "        age.append(line)\n",
    "    for line in fp4_a:\n",
    "        gender.append(line)\n",
    "    \n",
    "    for line in fp1:\n",
    "        if line=='\\n':\n",
    "            continue\n",
    "        fet_values=[]\n",
    "        line=line.replace('\\n','')\n",
    "        \n",
    "        # For Pre-Processing and handling retweet duplication:\n",
    "        if preProcessing(line):\n",
    "            line = preProcessing(line)\n",
    "        else:\n",
    "            var_count+=1\n",
    "            continue\n",
    "        \n",
    "        #line = preProcessing(line)\n",
    "        if file_counter%5000==0:\n",
    "            print line\n",
    "            print str(file_counter)\n",
    "        \n",
    "        text=nltk.word_tokenize(line)\n",
    "        pos_text=nltk.pos_tag(text)\n",
    "        \n",
    "        # No of Chars\n",
    "        fet_values.append(len(line))\n",
    "        \n",
    "        # No of Words\n",
    "        fet_values.append(len(pos_text))\n",
    "        \n",
    "        # No of wrong words\n",
    "        #fet_values.append(count_wrong(text))\n",
    "        fet_values.append(0)\n",
    "        \n",
    "        pos_stats=pos_statistics(pos_text)\n",
    "        \n",
    "        for i in pos_stats:\n",
    "            fet_values.append(i)\n",
    "        \n",
    "        F_measure=f_measure(pos_stats)\n",
    "        fet_values.append(F_measure)\n",
    "        \n",
    "        # Adding Aditya feats:\n",
    "        #fet_values.append(startsCapital(line))\n",
    "        fet_values.append(0)\n",
    "        fet_values.append(capitalized(text))\n",
    "        fet_values.append(endsWithPeriod(line))\n",
    "        fet_values.append(totalCapitals(text))\n",
    "        fet_values.append(perc_count_wrong(text))\n",
    "        fet_values.append(perc_of_punc_line(line))\n",
    "        fet_values.append(avg_word_len(text))\n",
    "        #fet_values.append(no_of_punc_line(line))\n",
    "        fet_values.append(0)\n",
    "        fet_values.append(countHashTags(line))\n",
    "        \n",
    "        fp3.write(age[var_count])\n",
    "        fp4.write(gender[var_count])\n",
    "        var_count+=1\n",
    "        for i in range(len(fet_values)):\n",
    "            fp2.write(str(fet_values[i]))\n",
    "            if i!=len(fet_values)-1:\n",
    "                fp2.write(\",\")\n",
    "            else:\n",
    "                fp2.write(\"\\n\")\n",
    "        file_counter+=1            \n",
    "    fp2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado civil: aborregao :)) Forges - 9 ENE 2014 URL via\n",
      "0\n",
      "The gravitational sucking of rock stardom on the wane? ;)\n",
      "5000\n",
      "Day 7 :: Brave #31Days // URL\n",
      "10000\n",
      "That Screen In Your Living Room URL via\n",
      "15000\n",
      "Multi Estate Extravaganza Online Internet Auction Va URL via\n",
      "20000\n",
      "Sobering facts: Climate Reports Forecast Dire Future URL - 375B tons CO2 into atmosphere since Industrial Age\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "words_to_fet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21]\n",
      "['FEMALE' 'MALE']\n",
      "['18-24' '23-50' '50-xx']\n",
      "[  5.50000000e+01   1.40000000e+01   2.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   4.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   1.00000000e+00   0.00000000e+00   0.00000000e+00   5.35000000e+01\n",
      "   1.42857143e-01   0.00000000e+00   1.42857143e-01   5.00000000e-01\n",
      "   1.81818182e-02   3.21428571e+00   0.00000000e+00]\n",
      "(27395,)\n",
      "(27395,)\n",
      "(27395, 19)\n",
      "5 nearest neighbor for age: \n",
      "Accuracy: 0.705420697208\n",
      "5 nearest neighbor for gender: \n",
      "Accuracy: 0.612885563059\n",
      "Logistic Regression for gender: \n",
      "Accuracy: 0.565249133053\n",
      "Logistic Regression for age: \n",
      "Accuracy: 0.689906917321\n",
      "SVM for gender: \n",
      "Accuracy: 0.609052746852\n",
      "SVM for age: \n",
      "Accuracy: 0.712903814565\n",
      "DT for gender: \n",
      "Accuracy: 0.65796678226\n",
      "DT for age: \n",
      "Accuracy: 0.662894688812\n",
      "Ensemble for age: \n",
      "Accuracy: 0.712356269392\n",
      "Ensemble for gender: \n",
      "Accuracy: 0.625661617083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Ensemble with Cross Validation\\neclf_a = VotingClassifier(estimators=[(\\'lr\\', clf2_a), (\\'knn\\', clf1_a), (\\'svc\\',clf3_a)], voting=\\'hard\\')\\neclf_g = VotingClassifier(estimators=[(\\'lr\\', clf2_g), (\\'knn\\', clf1_g), (\\'svc\\',clf3_g)], voting=\\'hard\\')\\nY_pred = cross_validation.cross_val_predict(eclf_g, X_all,Y_all_gender, cv=10)\\nprint \"Ensemble w/ Cross Validation for gender: \"\\nprint \"Accuracy: \"+str(accuracy_score(Y_all_gender,Y_pred))\\nY_pred = cross_validation.cross_val_predict(eclf_a, X_all,Y_all_age, cv=10)\\nprint \"Ensemble w/ Cross Validation for age: \"\\nprint \"Accuracy: \"+str(accuracy_score(Y_all_age,Y_pred))'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn import svm, cross_validation\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "fet_names=['Total Chars','Total Words','Total Punc']\n",
    "X_train=[]\n",
    "Y_gender=[]\n",
    "Y_age=[]\n",
    "cols = []\n",
    "\n",
    "features = ['num_chars','num_words', 'count_wrong','pos_stats',0,0,0,0,0,0,0,0,'f_measure','starts_capital',\n",
    "                'capitalized_text', 'ends_with','total_caps','perc_count_wrong','perc_punc_line',\n",
    "                'avg_word_len','num_punc_line', 'hashtag_count'\n",
    "               ]\n",
    "\n",
    "sub_features = ['num_chars','num_words', 'pos_stats','f_measure',\n",
    "                'capitalized_text', 'ends_with','total_caps','perc_count_wrong','perc_punc_line',\n",
    "                'avg_word_len', 'hashtag_count'\n",
    "               ]\n",
    "\n",
    "for feat_name in sub_features:\n",
    "    if feat_name is not 'pos_stats':\n",
    "        cols.append(features.index(feat_name))\n",
    "    else:\n",
    "        cols.extend([3,4,5,6,7,8,9,10,11])\n",
    "print cols\n",
    "fp2=open('gender_new.txt','r')\n",
    "fp3=open('age_modified.txt','r')\n",
    "for gender in fp2:\n",
    "\tgender=gender.replace('\\n','')\n",
    "\tY_gender.append(gender)\n",
    "for age in fp3:\n",
    "\tage=age.replace('\\n','')\n",
    "\tY_age.append(age)\n",
    "    \n",
    "# Encoding the labels    \n",
    "le=preprocessing.LabelEncoder()\n",
    "le.fit(Y_gender)\n",
    "print le.classes_\n",
    "Y_all_gender=le.transform(Y_gender)\n",
    "le.fit(Y_age)\n",
    "print le.classes_\n",
    "Y_all_age=le.transform(Y_age)\n",
    "X_all=np.loadtxt('features3.txt',delimiter=',', usecols = cols)\n",
    "print X_all[0]\n",
    "#X_all=np.loadtxt('features3.txt',delimiter=',')\n",
    "print Y_all_age.shape\n",
    "print Y_all_gender.shape\n",
    "print X_all.shape\n",
    "#print X_all[0]\n",
    "split=int(0.8*len(X_all))\n",
    "X_train=X_all[:split,:]\n",
    "X_test=X_all[split:,:]\n",
    "Y_train_gender=Y_all_gender[:split]\n",
    "Y_actual_gender=Y_all_gender[split:]\n",
    "Y_train_age=Y_all_age[:split]\n",
    "Y_actual_age=Y_all_age[split:]\n",
    "\n",
    "clf1_a = neighbors.KNeighborsClassifier()\n",
    "#clf.fit(X_train,Y_train)\n",
    "clf1_a.fit(X_train,Y_train_age)\n",
    "\n",
    "Y_pred=clf1_a.predict(X_test)\n",
    "#print accuracy_score(Y_actual,Y_pred)\n",
    "print \"5 nearest neighbor for age: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_actual_age,Y_pred))\n",
    "#print \"Precision: \"+str(precision_score(Y_actual_age, Y_pred, average='micro'))\n",
    "#print \"Recall: \"+str(recall_score(Y_actual_age, Y_pred, average='micro'))\n",
    "#print \"F1 score: \"+str(f1_score(Y_actual_age, Y_pred, average='micro'))\n",
    "\n",
    "clf1_g = neighbors.KNeighborsClassifier()\n",
    "#clf.fit(X_train,Y_train)\n",
    "clf1_g.fit(X_train,Y_train_gender)\n",
    "\n",
    "Y_pred=clf1_g.predict(X_test)\n",
    "print \"5 nearest neighbor for gender: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_actual_gender,Y_pred))\n",
    "#print \"Precision: \"+str(precision_score(Y_actual, Y_pred, average='micro'))\n",
    "#print \"Recall: \"+str(recall_score(Y_actual, Y_pred, average='micro'))\n",
    "#print \"F1 score: \"+str(f1_score(Y_actual, Y_pred, average='micro'))\n",
    "\n",
    "\n",
    "clf2_g = LogisticRegression()\n",
    "clf2_g.fit(X_train,Y_train_gender )\n",
    "Y_pred=clf2_g.predict(X_test)\n",
    "#print accuracy_score(Y_actual,Y_pred)\n",
    "print \"Logistic Regression for gender: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_actual_gender,Y_pred))\n",
    "#print \"Precision: \"+str(precision_score(Y_actual, Y_pred, average='micro'))\n",
    "#print \"Recall: \"+str(recall_score(Y_actual, Y_pred, average='micro'))\n",
    "#print \"F1 score: \"+str(f1_score(Y_actual, Y_pred, average='micro'))\n",
    "clf2_a = LogisticRegression()\n",
    "clf2_a.fit(X_train,Y_train_age )\n",
    "Y_pred=clf2_a.predict(X_test)\n",
    "print \"Logistic Regression for age: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_actual_age,Y_pred))\n",
    "\"\"\"\n",
    "# LogReg with Cross Validation\n",
    "\n",
    "Y_pred = cross_validation.cross_val_predict(LogisticRegression(), X_all,Y_all_gender, cv=10)\n",
    "print \"Logistic Regression w/ Cross Validation for gender: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_all_gender,Y_pred))\n",
    "Y_pred = cross_validation.cross_val_predict(LogisticRegression(), X_all,Y_all_age, cv=10)\n",
    "print \"Logistic Regression w/ Cross Validation for age: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_all_age,Y_pred))\n",
    "\"\"\"\n",
    "clf3_g = svm.SVC()\n",
    "clf3_g.fit(X_train,Y_train_gender )\n",
    "Y_pred=clf3_g.predict(X_test)\n",
    "#print accuracy_score(Y_actual,Y_pred)\n",
    "print \"SVM for gender: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_actual_gender,Y_pred))\n",
    "clf3_a = svm.SVC()\n",
    "clf3_a.fit(X_train,Y_train_age)\n",
    "Y_pred=clf3_a.predict(X_test)\n",
    "#print accuracy_score(Y_actual,Y_pred)\n",
    "print \"SVM for age: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_actual_age,Y_pred))\n",
    "#print \"Precision: \"+str(precision_score(Y_actual_age, Y_pred, average='micro'))\n",
    "#print \"Recall: \"+str(recall_score(Y_actual_age, Y_pred, average='micro'))\n",
    "#print \"F1 score: \"+str(f1_score(Y_actual_age, Y_pred, average='micro'))\n",
    "\n",
    "\"\"\"\n",
    "clf4_g = GaussianNB()\n",
    "clf4_g.fit(X_train,Y_train_gender )\n",
    "Y_pred=clf4_g.predict(X_test)\n",
    "#print accuracy_score(Y_actual,Y_pred)\n",
    "print \"NB for gender: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_actual_gender,Y_pred))\n",
    "clf4_a=GaussianNB()\n",
    "clf4_a.fit(X_train,Y_train_age)\n",
    "Y_pred=clf4_a.predict(X_test)\n",
    "#print accuracy_score(Y_actual,Y_pred)\n",
    "print \"NB for age: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_actual_age,Y_pred))\n",
    "\"\"\"\n",
    "clf5_g=DecisionTreeClassifier()\n",
    "clf5_g.fit(X_train,Y_train_gender )\n",
    "Y_pred=clf5_g.predict(X_test)\n",
    "#print accuracy_score(Y_actual,Y_pred)\n",
    "print \"DT for gender: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_actual_gender,Y_pred))\n",
    "clf5_a=DecisionTreeClassifier()\n",
    "clf5_a.fit(X_train,Y_train_age)\n",
    "Y_pred=clf5_a.predict(X_test)\n",
    "#print accuracy_score(Y_actual,Y_pred)\n",
    "print \"DT for age: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_actual_age,Y_pred))\n",
    "\n",
    "eclf_a = VotingClassifier(estimators=[('lr', clf2_a), ('knn', clf1_a), ('svc',clf3_a)], voting='hard')\n",
    "eclf_a.fit(X_train,Y_train_age)\n",
    "Y_pred=eclf_a.predict(X_test)\n",
    "print \"Ensemble for age: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_actual_age,Y_pred))\n",
    "\n",
    "eclf_g = VotingClassifier(estimators=[('lr', clf2_g), ('knn', clf1_g), ('svc',clf3_g)],voting='hard')\n",
    "eclf_g.fit(X_train,Y_train_gender)\n",
    "Y_pred=eclf_g.predict(X_test)\n",
    "print \"Ensemble for gender: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_actual_gender,Y_pred))\n",
    "\n",
    "\"\"\"# Ensemble with Cross Validation\n",
    "eclf_a = VotingClassifier(estimators=[('lr', clf2_a), ('knn', clf1_a), ('svc',clf3_a)], voting='hard')\n",
    "eclf_g = VotingClassifier(estimators=[('lr', clf2_g), ('knn', clf1_g), ('svc',clf3_g)], voting='hard')\n",
    "Y_pred = cross_validation.cross_val_predict(eclf_g, X_all,Y_all_gender, cv=10)\n",
    "print \"Ensemble w/ Cross Validation for gender: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_all_gender,Y_pred))\n",
    "Y_pred = cross_validation.cross_val_predict(eclf_a, X_all,Y_all_age, cv=10)\n",
    "print \"Ensemble w/ Cross Validation for age: \"\n",
    "print \"Accuracy: \"+str(accuracy_score(Y_all_age,Y_pred))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/aditya/Google Drive/UMass/First Semester/585/Project/WorkArea/Twitter_data/pan14-author-profiling-training-corpus-english-twitter-2014-04-16'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    eclf_a = VotingClassifier(estimators=[(\\'lr\\', clf2_a), (\\'knn\\', clf1_a), (\\'svc\\',clf3_a)], voting=\\'hard\\')\\n    eclf_a.fit(X_train,Y_train_age)\\n    Y_pred=eclf_a.predict(X_test)\\n    #print \"Ensemble for age: \"\\n    #print \"Accuracy: \"+str(accuracy_score(Y_actual_age,Y_pred))\\n    acc_Age = accuracy_score(Y_actual_age,Y_pred)\\n    if acc_Age > maxAcc_a:\\n        maxAcc_a = acc_Age\\n        featSet_a = sub_features\\n\\n\\n    eclf_g = VotingClassifier(estimators=[(\\'lr\\', clf2_g), (\\'knn\\', clf1_g), (\\'svc\\',clf3_g)],voting=\\'hard\\')\\n    eclf_g.fit(X_train,Y_train_gender)\\n    Y_pred=eclf_g.predict(X_test)\\n    #print \"Ensemble for gender: \"\\n    #print \"Accuracy: \"+str(accuracy_score(Y_actual_gender,Y_pred))\\n    acc_Gender = accuracy_score(Y_actual_gender,Y_pred)\\n    if acc_Gender > maxAcc_g:\\n        maxAcc_g = acc_Gender\\n        featSet_g = sub_features\\n        \\n    # Ensemble with Cross Validation\\n    eclf_a = VotingClassifier(estimators=[(\\'lr\\', clf2_a), (\\'knn\\', clf1_a), (\\'svc\\',clf3_a)], voting=\\'hard\\')\\n    eclf_g = VotingClassifier(estimators=[(\\'lr\\', clf2_g), (\\'knn\\', clf1_g), (\\'svc\\',clf3_g)], voting=\\'hard\\')\\n    Y_pred = cross_validation.cross_val_predict(eclf_g, X_all,Y_all_gender, cv=10)\\n    #print \"Ensemble w/ Cross Validation for gender: \"\\n    #print \"Accuracy: \"+str(accuracy_score(Y_all_gender,Y_pred))\\n    acc_Gender = accuracy_score(Y_all_gender,Y_pred)\\n    if acc_Gender > maxAcc_g:\\n        maxAcc_g = acc_Gender\\n        featSet_g = sub_features\\n\\n    Y_pred = cross_validation.cross_val_predict(eclf_a, X_all,Y_all_age, cv=10)\\n    #print \"Ensemble w/ Cross Validation for age: \"\\n    #print \"Accuracy: \"+str(accuracy_score(Y_all_age,Y_pred))\\n    acc_Age = accuracy_score(Y_all_age,Y_pred)\\n    if acc_Age > maxAcc_a:\\n        maxAcc_a = acc_Age\\n        featSet_a = sub_features\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Finding best accuracies\n",
    "\n",
    "def computeMaxAccuracy(sub_features):   \n",
    "    global maxAcc_a\n",
    "    global maxAcc_g\n",
    "    global featSet_a\n",
    "    global featSet_g\n",
    "    cols = []\n",
    "    features = ['num_chars','num_words', 'count_wrong','pos_stats',0,0,0,0,0,0,0,0,'f_measure','starts_capital',\n",
    "                'capitalized_text', 'ends_with','total_caps','perc_count_wrong','perc_punc_line',\n",
    "                'avg_word_len','num_punc_line','num_hashtags'\n",
    "               ]\n",
    "    \n",
    "    for feat_name in sub_features:\n",
    "        if feat_name is not 'pos_stats':\n",
    "            cols.append(features.index(feat_name))\n",
    "        else:\n",
    "            cols.extend([3,4,5,6,7,8,9,10,11])\n",
    "    print cols\n",
    "    \n",
    "    X_train=[]\n",
    "    Y_gender=[]\n",
    "    Y_age=[]\n",
    "    \n",
    "    fp2=open('gender.txt','r')\n",
    "    fp3=open('age.txt','r')\n",
    "    for gender in fp2:\n",
    "        gender=gender.replace('\\n','')\n",
    "        Y_gender.append(gender)\n",
    "    for age in fp3:\n",
    "        age=age.replace('\\n','')\n",
    "        Y_age.append(age)\n",
    "\n",
    "    # Encoding the labels    \n",
    "    le=preprocessing.LabelEncoder()\n",
    "    le.fit(Y_gender)\n",
    "    Y_all_gender=le.transform(Y_gender)\n",
    "    le.fit(Y_age)\n",
    "    Y_all_age=le.transform(Y_age)\n",
    "    X_all=np.loadtxt('features3.txt',delimiter=',', usecols = cols)\n",
    "    split=int(0.8*len(X_all))\n",
    "    X_train=X_all[:split,:]\n",
    "    X_test=X_all[split:,:]\n",
    "    Y_train_gender=Y_all_gender[:split]\n",
    "    Y_actual_gender=Y_all_gender[split:]\n",
    "    Y_train_age=Y_all_age[:split]\n",
    "    Y_actual_age=Y_all_age[split:]\n",
    "\n",
    "    clf1_a = neighbors.KNeighborsClassifier()\n",
    "    clf1_a.fit(X_train,Y_train_age)\n",
    "\n",
    "    Y_pred=clf1_a.predict(X_test)\n",
    "    #print accuracy_score(Y_actual,Y_pred)\n",
    "    #print \"5 nearest neighbor for age: \"\n",
    "    #print \"Accuracy: \"+str(accuracy_score(Y_actual_age,Y_pred))\n",
    "    acc_Age = accuracy_score(Y_actual_age,Y_pred)\n",
    "    if acc_Age > maxAcc_a:\n",
    "        maxAcc_a = acc_Age\n",
    "        featSet_a = sub_features\n",
    "    #print \"Precision: \"+str(precision_score(Y_actual_age, Y_pred, average='micro'))\n",
    "    #print \"Recall: \"+str(recall_score(Y_actual_age, Y_pred, average='micro'))\n",
    "    #print \"F1 score: \"+str(f1_score(Y_actual_age, Y_pred, average='micro'))\n",
    "\n",
    "    clf1_g = neighbors.KNeighborsClassifier()\n",
    "    #clf.fit(X_train,Y_train)\n",
    "    clf1_g.fit(X_train,Y_train_gender)\n",
    "    Y_pred=clf1_g.predict(X_test)\n",
    "    #print \"5 nearest neighbor for gender: \"\n",
    "    #print \"Accuracy: \"+str(accuracy_score(Y_actual_gender,Y_pred))\n",
    "    acc_Gender = accuracy_score(Y_actual_gender,Y_pred)\n",
    "    if acc_Gender > maxAcc_g:\n",
    "        maxAcc_g = acc_Gender\n",
    "        featSet_g = sub_features\n",
    "    \n",
    "    #print \"Precision: \"+str(precision_score(Y_actual, Y_pred, average='micro'))\n",
    "    #print \"Recall: \"+str(recall_score(Y_actual, Y_pred, average='micro'))\n",
    "    #print \"F1 score: \"+str(f1_score(Y_actual, Y_pred, average='micro'))\n",
    "\n",
    "    \"\"\"clf2_g = LogisticRegression()\n",
    "    #clf.fit(X_train,Y_train)\n",
    "    clf2_g.fit(X_train,Y_train_gender )\n",
    "    Y_pred=clf2_g.predict(X_test)\n",
    "    #print accuracy_score(Y_actual,Y_pred)\n",
    "    #print \"Logistic Regression for gender: \"\n",
    "    #print \"Accuracy: \"+str(accuracy_score(Y_actual_gender,Y_pred))\n",
    "    acc_Gender = accuracy_score(Y_actual_gender,Y_pred)\n",
    "    if acc_Gender > maxAcc_g:\n",
    "        maxAcc_g = acc_Gender\n",
    "        featSet_g = sub_features\n",
    "    \n",
    "    #print \"Precision: \"+str(precision_score(Y_actual, Y_pred, average='micro'))\n",
    "    #print \"Recall: \"+str(recall_score(Y_actual, Y_pred, average='micro'))\n",
    "    #print \"F1 score: \"+str(f1_score(Y_actual, Y_pred, average='micro'))\n",
    "    clf2_a = LogisticRegression()\n",
    "    #clf.fit(X_train,Y_train)\n",
    "    clf2_a.fit(X_train,Y_train_age )\n",
    "    Y_pred=clf2_a.predict(X_test)\n",
    "    #print \"Logistic Regression for age: \"\n",
    "    #print \"Accuracy: \"+str(accuracy_score(Y_actual_age,Y_pred))\n",
    "    acc_Age = accuracy_score(Y_actual_age,Y_pred)\n",
    "    if acc_Age > maxAcc_a:\n",
    "        maxAcc_a = acc_Age\n",
    "        featSet_a = sub_features\n",
    "    \"\"\"\n",
    "    # LogReg with Cross Validation\n",
    "\n",
    "    Y_pred = cross_validation.cross_val_predict(LogisticRegression(), X_all,Y_all_gender, cv=10)\n",
    "    print \"Logistic Regression w/ Cross Validation for gender: \"\n",
    "    print \"Accuracy: \"+str(accuracy_score(Y_all_gender,Y_pred))\n",
    "    acc_Gender = accuracy_score(Y_all_gender,Y_pred)\n",
    "    if acc_Gender > maxAcc_g:\n",
    "        maxAcc_g = acc_Gender\n",
    "        featSet_g = sub_features\n",
    "    \n",
    "    Y_pred = cross_validation.cross_val_predict(LogisticRegression(), X_all,Y_all_age, cv=10)\n",
    "    print \"Logistic Regression w/ Cross Validation for age: \"\n",
    "    print \"Accuracy: \"+str(accuracy_score(Y_all_age,Y_pred))\n",
    "    acc_Age = accuracy_score(Y_all_age,Y_pred)\n",
    "    if acc_Age > maxAcc_a:\n",
    "        maxAcc_a = acc_Age\n",
    "        featSet_a = sub_features\n",
    "\n",
    "    clf3_g = svm.SVC()\n",
    "    clf3_g.fit(X_train,Y_train_gender )\n",
    "    Y_pred=clf3_g.predict(X_test)\n",
    "    #print accuracy_score(Y_actual,Y_pred)\n",
    "    #print \"SVM for gender: \"\n",
    "    #print \"Accuracy: \"+str(accuracy_score(Y_actual_gender,Y_pred))\n",
    "    acc_Gender = accuracy_score(Y_actual_gender,Y_pred)\n",
    "    if acc_Gender > maxAcc_g:\n",
    "        maxAcc_g = acc_Gender\n",
    "        featSet_g = sub_features\n",
    "    \n",
    "    clf3_a = svm.SVC()\n",
    "    clf3_a.fit(X_train,Y_train_age)\n",
    "    Y_pred=clf3_a.predict(X_test)\n",
    "    #print accuracy_score(Y_actual,Y_pred)\n",
    "    #print \"SVM for age: \"\n",
    "    #print \"Accuracy: \"+str(accuracy_score(Y_actual_age,Y_pred))\n",
    "    acc_Age = accuracy_score(Y_actual_age,Y_pred)\n",
    "    if acc_Age > maxAcc_a:\n",
    "        maxAcc_a = acc_Age\n",
    "        featSet_a = sub_features\n",
    "\n",
    "    #print \"Precision: \"+str(precision_score(Y_actual_age, Y_pred, average='micro'))\n",
    "    #print \"Recall: \"+str(recall_score(Y_actual_age, Y_pred, average='micro'))\n",
    "    #print \"F1 score: \"+str(f1_score(Y_actual_age, Y_pred, average='micro'))\n",
    "\"\"\"\n",
    "    eclf_a = VotingClassifier(estimators=[('lr', clf2_a), ('knn', clf1_a), ('svc',clf3_a)], voting='hard')\n",
    "    eclf_a.fit(X_train,Y_train_age)\n",
    "    Y_pred=eclf_a.predict(X_test)\n",
    "    #print \"Ensemble for age: \"\n",
    "    #print \"Accuracy: \"+str(accuracy_score(Y_actual_age,Y_pred))\n",
    "    acc_Age = accuracy_score(Y_actual_age,Y_pred)\n",
    "    if acc_Age > maxAcc_a:\n",
    "        maxAcc_a = acc_Age\n",
    "        featSet_a = sub_features\n",
    "\n",
    "\n",
    "    eclf_g = VotingClassifier(estimators=[('lr', clf2_g), ('knn', clf1_g), ('svc',clf3_g)],voting='hard')\n",
    "    eclf_g.fit(X_train,Y_train_gender)\n",
    "    Y_pred=eclf_g.predict(X_test)\n",
    "    #print \"Ensemble for gender: \"\n",
    "    #print \"Accuracy: \"+str(accuracy_score(Y_actual_gender,Y_pred))\n",
    "    acc_Gender = accuracy_score(Y_actual_gender,Y_pred)\n",
    "    if acc_Gender > maxAcc_g:\n",
    "        maxAcc_g = acc_Gender\n",
    "        featSet_g = sub_features\n",
    "        \n",
    "    # Ensemble with Cross Validation\n",
    "    eclf_a = VotingClassifier(estimators=[('lr', clf2_a), ('knn', clf1_a), ('svc',clf3_a)], voting='hard')\n",
    "    eclf_g = VotingClassifier(estimators=[('lr', clf2_g), ('knn', clf1_g), ('svc',clf3_g)], voting='hard')\n",
    "    Y_pred = cross_validation.cross_val_predict(eclf_g, X_all,Y_all_gender, cv=10)\n",
    "    #print \"Ensemble w/ Cross Validation for gender: \"\n",
    "    #print \"Accuracy: \"+str(accuracy_score(Y_all_gender,Y_pred))\n",
    "    acc_Gender = accuracy_score(Y_all_gender,Y_pred)\n",
    "    if acc_Gender > maxAcc_g:\n",
    "        maxAcc_g = acc_Gender\n",
    "        featSet_g = sub_features\n",
    "\n",
    "    Y_pred = cross_validation.cross_val_predict(eclf_a, X_all,Y_all_age, cv=10)\n",
    "    #print \"Ensemble w/ Cross Validation for age: \"\n",
    "    #print \"Accuracy: \"+str(accuracy_score(Y_all_age,Y_pred))\n",
    "    acc_Age = accuracy_score(Y_all_age,Y_pred)\n",
    "    if acc_Age > maxAcc_a:\n",
    "        maxAcc_a = acc_Age\n",
    "        featSet_a = sub_features\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "maxAcc_a = 0\n",
    "maxAcc_g = 0\n",
    "featSet_a = []\n",
    "featSet_g = []\n",
    "    \n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(3, len(s)+1)))\n",
    "\n",
    "def createFeatures():\n",
    "    global maxAcc_a\n",
    "    global maxAcc_g\n",
    "    global featSet_a\n",
    "    global featSet_g\n",
    "    \n",
    "    # Uncomment below for creating features for a new dataset!\n",
    "    #words_to_fet()\n",
    "    features = ['num_chars','num_words', 'count_wrong','pos_stats','f_measure','starts_capital',\n",
    "                'capitalized_text', 'ends_with','total_caps','perc_count_wrong','perc_punc_line',\n",
    "                'avg_word_len','num_punc_line','num_hashtags'\n",
    "               ]\n",
    "    count = 0\n",
    "    for sub_feats in powerset(features)[::-1]:\n",
    "        count += 1\n",
    "        if count > 10:\n",
    "            break\n",
    "        computeMaxAccuracy(sub_feats)\n",
    "    return maxAcc_a, maxAcc_g, [i for i in featSet_a], [i for i in featSet_g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5531, 5479]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-96038be981be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreateFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-c1a9c2893e4f>\u001b[0m in \u001b[0;36mcreateFeatures\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mcomputeMaxAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaxAcc_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxAcc_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatSet_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatSet_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-fd59a36f4c97>\u001b[0m in \u001b[0;36mcomputeMaxAccuracy\u001b[0;34m(sub_features)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m#print \"5 nearest neighbor for age: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m#print \"Accuracy: \"+str(accuracy_score(Y_actual_age,Y_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0macc_Age\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_actual_age\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0macc_Age\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxAcc_a\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mmaxAcc_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_Age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aditya/anaconda/envs/NLP2.7Env/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aditya/anaconda/envs/NLP2.7Env/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aditya/anaconda/envs/NLP2.7Env/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5531, 5479]"
     ]
    }
   ],
   "source": [
    "createFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
