{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set 1, Intro to NLP, 2017\n",
    "\n",
    "#### This is due on September 22nd at 11PM. Please see detailed submission instructions below.  100 points total.\n",
    "\n",
    "##### How to do this problem set:\n",
    "\n",
    "- What version of Python should I use? 2.7\n",
    "\n",
    "- Most of these questions require writing Python code and computing results, and the rest of them have textual answers. To generate the answers, you will have to fill out a supporting file, `hw_1.py`.\n",
    "\n",
    "- For all of the textual answers you have to fill out have placeholder text which says \"Answer in one or two sentences here.\" For each question, you need to replace \"Answer in one or two sentences here\" with your answer.\n",
    "\n",
    "- Write all the answers in this ipython notebook. Once you are finished (1) Generate a PDF via (File -> Download As -> PDF) and upload to Gradescope (2)Turn in `hw_1.py` and `hw_1.ipynb` on Moodle.\n",
    "  \n",
    "- **Important:** Check your PDF before you turn it in to gradescope to make sure it exported correctly. If ipyhton notebook gets confused about your syntax it will sometimes terminate the PDF creation routine early. You are responsible for checking for these errors. If your whole PDF does not print, try running `$jupyter nbconvert --to pdf hw_1.ipynb` to identify and fix any syntax errors that might be causing problems.\n",
    "\n",
    "- **Important:** When creating your final version of the PDF to hand in, please do a fresh restart and execute every cell in order. Then you'll be sure it's actually right. One convenient way to do this is by clicking `Cell -> Run All` in the notebook menu.\n",
    " \n",
    "- This assignment is designed so that you can run all cells in a few minutes of computation time. If it is taking longer than that, you probably have made a mistake in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Academic honesty \n",
    "\n",
    "- We will audit the Moodle code from a few dozen students, chosen at random. The audits will check that the code you wrote and turned on Moodle generates the answers you turn in on your Gradescope PDF. If you turn in correct answers on your PDF without code that actually generates those answers, we will consider this a potential case of cheating. See the course page for honesty policies.\n",
    "\n",
    "- We will also run automatic checks of code on Moodle for plagiarism. Copying code from others is considered a serious case of cheating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell! It sets some things up for you.\n",
    "\n",
    "# This code makes plots appear inline in this document rather than in a new window.\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import division  # this line is important to avoid unexpected behavior from division\n",
    "\n",
    "# This code imports your work from hw_1.py\n",
    "from hw_1 import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5, 4) # set default size of plots\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! You have 12500 pos reviews in large_movie_review_dataset/train/pos\n",
      "Great! You have 12500 neg reviews in large_movie_review_dataset/train/neg\n"
     ]
    }
   ],
   "source": [
    "# download the IMDB large movie review corpus from the class webpage to a file location on your computer\n",
    "\n",
    "PATH_TO_DATA = 'large_movie_review_dataset'  # set this variable to point to the location of the IMDB corpus on your computer\n",
    "POS_LABEL = 'pos'\n",
    "NEG_LABEL = 'neg'\n",
    "TRAIN_DIR = os.path.join(PATH_TO_DATA, \"train\")\n",
    "TEST_DIR = os.path.join(PATH_TO_DATA, \"test\")\n",
    "\n",
    "for label in [POS_LABEL, NEG_LABEL]:\n",
    "    if len(os.listdir(TRAIN_DIR + \"/\" + label)) == 12500:\n",
    "        print \"Great! You have 12500 {} reviews in {}\".format(label, TRAIN_DIR + \"/\" + label)\n",
    "    else:\n",
    "        print \"Oh no! Something is wrong. Check your code which loads the reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right away, this film was ridiculous. Not that it didn't have redeeming aspects",
      " For example, the best thing about this film was the beautiful background scenery. Anyone not living on the East Coast should know the South doesn't have beautiful mountains like those found in the West. I knew it was Utah right off the bat, but perhaps Dalton couldn't suppress his English accent, so they had to excuse it by saying this was a southern town. Subverting his accent into a Southern one was easier. Sure the film has plot twists, but its phony sense of place was something I couldn't get past. It's not like Utah doesn't have meth labs... so why the writers thought it necessary to pretend it was in the South is beyond me. <br /><br />One other thing in action pictures always puzzles me. Why do they always make the \"cocking\" sound effect when the character pulls out an automatic handgun? It seemed every other sound effect in this movie was a \"chuk-chich\" signifying a 9mm was loaded and ready to fire. Of course, the weapons already had rounds chambered so this was unnecessary. <br /><br />Lastly, the pyrotechnics were WAY over the top. But hey, this film was targeted to a certain 'market segment' I suppose... It's too bad. Each of the actors can act, but this film was lame.\n"
     ]
    }
   ],
   "source": [
    "# Actually reading the data you are working with is an important part of NLP! Let's look at one of these reviews\n",
    "\n",
    "print open(TRAIN_DIR + \"/neg/3740_2.txt\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One: Intro to NLP in Python: types, tokens and Zipf's law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Types and tokens\n",
    "\n",
    "One major part of any NLP project is word tokenization. Word tokenization is the task of segmenting text into individual words, called tokens. In this assignment, we will use simple whitespace tokenization. You will have a chance to improve this for extra credit at the end of the assigment. Take a look at the `tokenize_doc` function in `hw_1.py`. **You should not modify tokenize_doc** but make sure you understand what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "both\n",
      "computer\n",
      "abstract.\n",
      "science\n",
      "is\n",
      "practical\n"
     ]
    }
   ],
   "source": [
    "# We have provided a tokenize_doc function in hw_1.py. Here is a short demo of how it works\n",
    "\n",
    "d1 = \"This SAMPLE doc has   words tHat  repeat repeat\"\n",
    "bow = tokenize_doc(d1)\n",
    "\n",
    "assert bow['this'] == 1\n",
    "assert bow['sample'] == 1\n",
    "assert bow['doc'] == 1\n",
    "assert bow['has'] == 1\n",
    "assert bow['words'] == 1\n",
    "assert bow['that'] == 1\n",
    "assert bow['repeat'] == 2\n",
    "\n",
    "bow2 = tokenize_doc(\"Computer science is both practical and abstract.\")\n",
    "for b in bow2:\n",
    "    print b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1 (5 points)**\n",
    "\n",
    "Now we are going to count the word types and word tokens in the corpus. In the cell below, use the `word_counts` dictionary variable to store the count of each word in the corpus.\n",
    "Use the `tokenize_doc` function to break documents into tokens. \n",
    "\n",
    "`word_counts` keeps track of how many times a word type appears across the corpus. For instance, `word_counts[\"dog\"]` should store the number 990 -- the count of how many times the word `dog` appears in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "word_counts = defaultdict(float)  # you might want to use a defaultdict instead https://docs.python.org/2/library/collections.html\n",
    "                  # defaultdicts are often useful for NLP in python\n",
    "\n",
    "\n",
    "for label in [POS_LABEL, NEG_LABEL]:\n",
    "    for directory in [TRAIN_DIR, TEST_DIR]:\n",
    "        for fn in glob.glob(directory + \"/\" + label + \"/*txt\"):\n",
    "            fp=open(fn,'r')\n",
    "            #print \"Working??\"+ str(fn)\n",
    "            data=fp.read()\n",
    "            doc_tokens=tokenize_doc(data)\n",
    "            for token in doc_tokens.keys():\n",
    "                word_counts[token]+=doc_tokens[token]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay! there are 990.0 total instances of the word type dog in the corpus\n"
     ]
    }
   ],
   "source": [
    "# you should see 990 instances of the word type \"dog\" in the corpus. (updated 9/13)\n",
    "if word_counts[\"dog\"] == 990:\n",
    "    print \"yay! there are {} total instances of the word type dog in the corpus\".format(word_counts[\"dog\"])\n",
    "else:\n",
    "    print \"hrm. Something seems off. Double check your code\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2 (5 points)**\n",
    "\n",
    "Fill out the functions `n_word_types` and `n_word_tokens` in `hw_1.py`. These functions return the total number of word types and tokens in the corpus. **important** The autoreload \"magic\" that you setup early in the assignment should automatically reload functions as you make changes and save. If you run into trouble you can always restart the notebook and clear any .pyc files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 391997 word types in the corpus\n",
      "there are 11557403.0 word tokens in the corpus\n"
     ]
    }
   ],
   "source": [
    "print \"there are {} word types in the corpus\".format(n_word_types(word_counts))\n",
    "print \"there are {} word tokens in the corpus\".format(n_word_tokens(word_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3 (5 points)**\n",
    "\n",
    "You should see a much higher number of tokens than types. Why is that? \n",
    "\n",
    "Words very often repeat in sentences. So the number of different kinds of words (\"word_types\") will be less than the total words used (\"word_tokens\"). (As an example, the token 'words' (one word_type) appears three times in my last 2 sentences of the answer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zipf's Law\n",
    "\n",
    "**Question 1.4 (5 points)**\n",
    "\n",
    "In this section, you will verify a key statistical properties of text: [Zipf's Law](https://en.wikipedia.org/wiki/Zipf%27s_law).\n",
    "\n",
    "Zipf's Law describes the relations between the frequency rank of words and frequency value of words.  For a word $w$, its frequency is inversely proportional to its rank:\n",
    "\n",
    "$$count_w = K \\frac{1}{rank_w}$$\n",
    "or in other words\n",
    "$$\\log(count_w) = K - \\log(rank_w)$$\n",
    "\n",
    "for some constant $K$, specific to the corpus and how words are being defined.\n",
    "\n",
    "Therefore, if Zipf's Law holds, after sorting the words descending on frequency, word frequency decreases in an approximately linear fashion under a log-log scale.\n",
    "\n",
    "Please make such a log-log plot by ploting the rank versus frequency.  Use a scatter plot where the x-axis is the *log(rank)*, and y-axis is *log(frequency)*.  You should get this information from `word_counts`; for example, you can take the individual word counts and sort them.  dict methods `.items()` and/or `values()` may be useful.  (Note that it doesn't really matter whether ranks start at 1 or 0 in terms of how the plot comes out.) You can check your results by comparing your plots to ones on Wikipedia; they should look qualitatively similar.\n",
    "\n",
    "*Please remember to label the meaning of the x-axis and y-axis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 638845.0), ('a', 316607.0), ('and', 313603.0), ('of', 286653.0), ('to', 264569.0), ('is', 204867.0), ('in', 179802.0), ('i', 141578.0), ('this', 138477.0), ('that', 130133.0)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEZCAYAAAAjY2YEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTSIiIiIiIiIiIiIiIiIiIiIiLc7/Axp40OqIrOsRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f03f30a6f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "x = []\n",
    "y = []\n",
    "X_LABEL = \"Ranks of word_types\"\n",
    "Y_LABEL = \"Frequency count of the word_type\"\n",
    "\n",
    "# implement me! you should fill the x and y arrays. Add your code here\n",
    "\n",
    "tup_wc=word_counts.items()\n",
    "tup_wc.sort(key=lambda tup: tup[1],reverse=True)\n",
    "count=1\n",
    "for tup in tup_wc:\n",
    "    x.append(count)\n",
    "    y.append(tup[1])\n",
    "    count+=1\n",
    "print tup_wc[0:10]\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(X_LABEL)\n",
    "plt.ylabel(Y_LABEL)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5 (5 points)**\n",
    "\n",
    "You should see some discountinuities on the left and right sides of this figure.  Why are we seeing them on the left?  Why are we seeing them on the right?  On the right, what are those \"ledges\"?\n",
    "\n",
    "The discontinuity on the left denotes that the difference between word counts initially is very high (so high that it is noticeable even on a log-log scale .Like 'that' appears 6Lakh times while the next rank 'a' appears 3Lakh times roughly half of the previous one). The ones on the right show that the frequency falls off very rapidly as we approach uncommon words. The drop is noticeable as discontinuities. The ledges on the right denote words, having same frequencies (As an example rare words are used only once in the whole corpus and all these have frequency as 1). They effectively all share the same rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the homework will walk you through coding a Naive Bayes classifier that can distinguish between postive and negative reviews (at some level of accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1 (5 pts) ** To start, implement the `update_model` function in `hw_1.py`. Make sure to read the function comments so you know what to update. Also review the NaiveBayes class variables in the `def __init__` method of the NaiveBayes class  to get a sense of which statistics are important to keep track of. Once you have implemented `update_model`, run the train model function using the code below. You’ll need to provide the path to the dataset you downloaded to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORTING CORPUS STATISTICS\n",
      "NUMBER OF DOCUMENTS IN POSITIVE CLASS: 12500.0\n",
      "NUMBER OF DOCUMENTS IN NEGATIVE CLASS: 12500.0\n",
      "NUMBER OF TOKENS IN POSITIVE CLASS: 2958730.0\n",
      "NUMBER OF TOKENS IN NEGATIVE CLASS: 2885734.0\n",
      "VOCABULARY SIZE: NUMBER OF UNIQUE WORDTYPES IN TRAINING CORPUS: 252165\n",
      "Great! The vocabulary size is 252165\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(PATH_TO_DATA, tokenizer=tokenize_doc)\n",
    "nb.train_model()\n",
    "\n",
    "if len(nb.vocab) == 252165:\n",
    "    print \"Great! The vocabulary size is {}\".format(252165)\n",
    "else:\n",
    "    print \"Oh no! Something seems off. Double check your code before continuing. Maybe a mistake in update_model?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory analysis\n",
    "\n",
    "Let’s begin to explore the count statistics stored by the update model function. Use the provided `top_n` function to find the top 10 most common words in the positive class and top 10 most common words in the negative class. You don't have to code anything to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 WORDS FOR CLASS pos:\n",
      " the 165803.0\n",
      " and 87022.0\n",
      " a 82054.0\n",
      " of 76155.0\n",
      " to 65869.0\n",
      " is 55785.0\n",
      " in 48420.0\n",
      " i 33143.0\n",
      " it 32795.0\n",
      " that 32702.0\n",
      "\n",
      "TOP 10 WORDS FOR CLASS neg:\n",
      " the 156385.0\n",
      " a 77895.0\n",
      " and 71534.0\n",
      " of 68304.0\n",
      " to 68097.0\n",
      " is 48385.0\n",
      " in 42103.0\n",
      " i 37335.0\n",
      " this 37301.0\n",
      " that 33585.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"TOP 10 WORDS FOR CLASS \" + POS_LABEL + \":\"\n",
    "for tok, count in nb.top_n(POS_LABEL, 10):\n",
    "    print '', tok, count\n",
    "print ''\n",
    "\n",
    "print \"TOP 10 WORDS FOR CLASS \" + NEG_LABEL + \":\"\n",
    "for tok, count in nb.top_n(NEG_LABEL, 10):\n",
    "    print '', tok, count\n",
    "print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2 (5 points)**\n",
    "\n",
    "Will the top 10 words of the positive/negative classes help discriminate between the two classes? Do you imagine that processing other English text will result in a similar phenomenon?\n",
    "\n",
    "No, they won't. Using these as features will not help in classifying because these are common words of English and will occur in both the types of reviews. Processing other English text will also result in a similar top_words of classes and they also won't be useful in classifying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3 (5 pts) **\n",
    "\n",
    "The Naive Bayes model assumes that all features are conditionally independent given the class label. For our purposes, this means that the probability of seeing a particular word in a document with class label $y$ is independent of the rest of the words in that document. Implement the `p_word_given_label` function. This function calculates P (w|y) (i.e., the probability of seeing word w in a document given the label of that document is y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your `p_word_given_label` function to compute the probability of seeing the word “fantastic” given each sentiment label. Repeat the computation for the word “boring.” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P('fantastic'|pos): 0.000154458162793\n",
      "P('fantastic'|neg): 3.77720191813e-05\n",
      "P('boring'|pos): 6.18508616873e-05\n",
      "P('boring'|neg): 0.000287275265149\n"
     ]
    }
   ],
   "source": [
    "print \"P('fantastic'|pos):\",  nb.p_word_given_label(\"fantastic\", POS_LABEL)\n",
    "print \"P('fantastic'|neg):\",  nb.p_word_given_label(\"fantastic\", NEG_LABEL)\n",
    "print \"P('boring'|pos):\",  nb.p_word_given_label(\"boring\", POS_LABEL)\n",
    "print \"P('boring'|neg):\",  nb.p_word_given_label(\"boring\", NEG_LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which word has a higher probability given the positive class, fantastic or boring? Which word has a higher probability given the negative class? Is this what you would expect?\n",
    "\n",
    "'fantastic' for +ve class and 'boring' for -ve class. It is the expected outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4 (5 pts)**\n",
    "\n",
    "In the next cell, compute the probability of the word \"car-thievery\" in the positive training data and negative training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P('car-thievery'|pos): 3.3798285075e-07\n",
      "P('car-thievery'|neg): 0.0\n"
     ]
    }
   ],
   "source": [
    "print \"P('car-thievery'|pos):\",  nb.p_word_given_label(\"car-thievery\", POS_LABEL)\n",
    "print \"P('car-thievery'|neg):\",  nb.p_word_given_label(\"car-thievery\", NEG_LABEL)\n",
    "#print \"P('cliche'|neg):\",  nb.p_word_given_label(\"cliche\", NEG_LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about \"P('car-thievery'|neg)\"? Why do you see this number? What would happen if we took the log of \"P('car-thievery'|neg)\"? What would happen if we multiplied \"P('car-thievery'|neg)\" by \"P('cliche'|neg)\"? Why might these operations cause problems for a Naive Bayes classifier?\n",
    "\n",
    "P('car-thievery'|neg)=0.0 because the phrase 'car-thievery' does not occur in any negatively tagged document of the corpus. Zeros cause a problem, because taking logarithms is common in NLP and log(0) makes the result as -ve infinity. And even 'one' such term like this, will make the whole product zero (when multiplied by P('car-thievery'|neg)). Thus because of one such a non-existent phrase many of our probabilities become 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5 (5 pts)**\n",
    "\n",
    "We can address the issues from question 2.4 with psuedocounts. A psuedocount is a fixed amount added to the count of each word stored in our model. Psuedocounts are used to help smooth calculations involving words for which there is little data. Implement\n",
    "`p_word_given_label_and_psuedocount` and then run the next cell. Hint: look at the slides from the lecture on pseudocounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P('car-thievery'|neg): 3.18684572066e-07\n"
     ]
    }
   ],
   "source": [
    "print \"P('car-thievery'|neg):\",  nb.p_word_given_label_and_pseudocount(\"car-thievery\", NEG_LABEL, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6 (getting ready for question 2.10)**\n",
    "\n",
    "*Prior and Likelihood* \n",
    "\n",
    "As noted before, the Naive Bayes model assumes that all words in a document are independent of one another given the document’s label. Because of this we can write the likelihood of a document as:\n",
    "\n",
    "$P(w_{d1},\\cdots,w_{dn}|y_d) = \\prod_{i=1}^{n}P(w_{di}|y_d)$\n",
    "\n",
    "However, if a document has a lot of words, the likelihood will become extremely small and we’ll encounter numerical underflow. Underflow is a common problem when dealing with prob- abilistic models; if you are unfamiliar with it, you can get a brief overview on [Wikipedia](https:/en.wikipedia.org/wiki/Arithmetic_underflow). To deal with underflow, a common transformation is to work in log-space.\n",
    "\n",
    "$\\log[P(w_{d1},\\cdots,w_{dn}|y_d)] = \\sum_{i=1}^{n}\\log[P(w_{di}|y_d)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the `log_likelihood` function (Hint: it should make calls to the p word given label and psuedocount function).\n",
    "Implement the `log_prior` function. This function takes a class label and returns the log of the fraction of the training documents that are of that label.\n",
    "\n",
    "There is nothing to print out for this question. But you will use these functions in a moment..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7 (5 pts) **\n",
    "\n",
    "Naive Bayes is a model that tells us how to compute the posterior\n",
    "probability of a document being of some label (i.e.,\n",
    "$P(y_d|\\mathbf{w_d})$).  Specifically, we do so using bayes rule:\n",
    "\n",
    "  $P(y_d|\\mathbf{w_d}) = \\frac{P(y_d)P(\\mathbf{w_d}|y_d)}{P(\\mathbf{w_d})}$\n",
    "\n",
    "In the previous section you implemented functions to compute both\n",
    "the log prior ($\\log[P(y_d)]$) and the log likelihood\n",
    "($\\log[P( \\mathbf{w_d} |y_d)]$ ). Now, all your missing is the\n",
    "*normalizer*, $P(\\mathbf{w_d})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive the normalizer by expanding $P(\\mathbf{w_d})$. You will have to use \"MathJax\" to write out the equations. MathJax is very similar to LaTeX. 99% of the MathJax you will need to write for this course (and others at U Mass) is included in the first answer of [this](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) tutorial. MathJax and LaTeX can be annoying first, but once you get a little practice, using these tools will feel like second nature.\n",
    "\n",
    "\n",
    "Derive the normalizer by expanding $P(\\mathbf{w_d})$. Fill out the answer with MathJax here\n",
    "\n",
    "$P(\\mathbf{w_d})$=$P(\\mathbf{w_1, w_2, ...w_dn})$=$P(\\mathbf{w_1})$*$P(\\mathbf{w_2}*....)$=$\\prod_{i=1}^n P(\\mathbf{w_di})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.8 (5 pts)**\n",
    "\n",
    "One way to classify a document is to compute the unnormalized log posterior for both labels and take the argmax (i.e., the label that yields the higher unnormalized log posterior). The unnormalized log posterior is the sum of the log prior and the log likelihood of the document. Why don’t we need to compute the log normalizer here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizer is like a constant term, which is same for both labels. I think it of as a term to bring back the numerator, with range 0 to 1. Since, we are just comparing terms, the common normalizer for both the terms should NOT be a problem and the raw_unnormalized version should be enough for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.9 (15 pts)**\n",
    "\n",
    "Implement the `unnormalized_log_posterior` function and the `classify` function. The `classify` function should use the unnormalized log posteriors but should not compute the normalizer. Once you implement the `classify` function, we'd like to evaluate its accuracy. `evaluate_classifier_accuracy` is implemented for you so you don't need to change that method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.94\n"
     ]
    }
   ],
   "source": [
    "print nb.evaluate_classifier_accuracy(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.10 (5 pts)**\n",
    "\n",
    "Try evaluating your model again with a pseudocount parameter of 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.836\n"
     ]
    }
   ],
   "source": [
    "print nb.evaluate_classifier_accuracy(500.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the accuracy go up or down when the pseudo count parameter is raised to 500? Why do you think this is?\n",
    "\n",
    "It goes DOWN. Maybe because, a high alpha like 500 starts to become comparable with the count term in the probability. Higher alphas lead to too much smoothing. This is bad, because now all words start to get more-or-less similar probabilities (As an exaggerated example, when we put alpha like a million, the other terms don't matter. Each word will get uniform probability.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.11 (5 pts)**\n",
    "\n",
    "Our trained model can be queried to do exploratory data analysis. We\n",
    "saw that the top 10 most common words for each class were not very\n",
    "discriminative. Often times, a more descriminative statistic is a\n",
    "word's likelihood ratio. A word's likelihood ratio is defined as\n",
    "\n",
    "$LR(w)=\\frac{P(w|y=\\mathrm{pos})}{P(w|y=\\mathrm{neg})}$\n",
    "\n",
    "A word with $LR=5$ is five times more likely to appear in a positive\n",
    "review than it is in a negative review; a word with $LR=0.33$ is one\n",
    "third as likely to appear in a positive review than a negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIKEHOOD RATIO OF 'fantastic': 4.06898088596\n",
      "LIKEHOOD RATIO OF 'boring': 0.216646954101\n",
      "LIKEHOOD RATIO OF 'the': 1.03611983814\n",
      "LIKEHOOD RATIO OF 'to': 0.94529239345\n"
     ]
    }
   ],
   "source": [
    "# Implement the nb.likelihod_ratio function and use it to investigate the likelihood ratio of \"fantastic\" and \"boring\"\n",
    "print \"LIKEHOOD RATIO OF 'fantastic':\", nb.likelihood_ratio('fantastic', 1.0)\n",
    "print \"LIKEHOOD RATIO OF 'boring':\", nb.likelihood_ratio('boring', 1.0)\n",
    "print \"LIKEHOOD RATIO OF 'the':\", nb.likelihood_ratio('the', 1.0)\n",
    "print \"LIKEHOOD RATIO OF 'to':\", nb.likelihood_ratio('to', 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it make sense that $LR$('fantastic') $>$ $LR$('to')? \n",
    "\n",
    "'fantastic' is more prevalent in positive reviews and not present in negative reviews wheras the word 'to' is present in both types of documents. Thus the word 'fantastic' is more clearly able to classify the documents while the universailty of the word 'to' makes it a weak feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 2.12 (15 pts)** \n",
    "\n",
    "Find a review that your classifier got wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual label: pos\n",
      "predicted label: neg\n",
      "This movie would had worked much better if this was the first Critters movie, this is a low-budget movie with only two (2) Critters shown on-screen. Why this looks like a fail is because this is the last Critters movie and it's so low-budget that it seems the director made the whole movie with his own pocket money. However, I did like this movie, I compare it mostly with the third movie (which were bad). Critters 4 have a more serious tone in it, the first half of the movie (even without seeing one Critter yet) you have a scary feeling watching it, too bad they didn't \"milk\" out the Critters, I mean even if they only had two (2) puppets they could still have used them on-screen a lot more. The Critters also have different deaths in this movie which made this a little special, especially at the end with the frozen Critter. Ug has a promotion in this part and is different in this movie which took me by surprise. Lastly I liked this one because it also has some kind of conclusion to the series, so at least we won't see a Critters 5 anymore. Oh, one last thing, I missed one scene in this movie, we never see a Critter shoot a spike from its back, maybe these puppets didn't have that feature, but I was very disappointed not seeing that (in Critters 3 we see a lot of spike shooting, which was the only good thing I liked about that movie).\n",
      "LIKEHOOD RATIO OF 'fail': 0.5661403913\n",
      "LIKEHOOD RATIO OF 'surprise': 1.31718481309\n",
      "LIKEHOOD RATIO OF 'low-budget': 0.522437879813\n",
      "LIKEHOOD RATIO OF 'bad': 0.271422120829\n"
     ]
    }
   ],
   "source": [
    "# in this cell, print out a review that your classifier got wrong. Print out the text of the review along with the label\n",
    "nb.print_wrong_review(1.0)\n",
    "print \"LIKEHOOD RATIO OF 'fail':\", nb.likelihood_ratio('fail', 1.0)\n",
    "print \"LIKEHOOD RATIO OF 'surprise':\", nb.likelihood_ratio('surprise', 1.0)\n",
    "print \"LIKEHOOD RATIO OF 'low-budget':\", nb.likelihood_ratio('low-budget', 1.0)\n",
    "print \"LIKEHOOD RATIO OF 'bad':\", nb.likelihood_ratio('bad', 1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are two reasons your system might have misclassified this example? What improvements could you make that may help your system classify this example correctly? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many times words like 'fail' and 'bad' are present in the review. | Expanding the context helps. \"Looks like a fail\", \"which were bad\" phrases might help in classifying it correctly as positive.\n",
    "\n",
    "\n",
    "There is a lot of -ve criticism for the prequels of the Critters franchise | Identifying the proper subject of the sentences helps associate the -ve criticism to the earlier films of the franchise and not this current film."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra credit (up to 10 points) **\n",
    "\n",
    "If you don't want to do the extra credit, you can stop here! Otherwise... keep reading... \n",
    " \n",
    "In this assignment, we use whitespace tokenization to create a bag-of-unigrams representation for the movie reviews. It is possible to improve this represetation to improve your classifier's performance. Use your own code or an external library such as nltk to perform tokenization, text normalization, word filtering, etc. Fill out your work in `def tokenize_doc_and_more` (below) and then show improvement by running the following.\n",
    "\n",
    "`nb = NaiveBayes(PATH_TO_DATA, tokenizer=tokenize_doc_and_more)\n",
    "nb.train_model()\n",
    "nb.evaluate_classifier_accuracy(1.0)\n",
    "`\n",
    "\n",
    "Roughly speaking, the larger performance improvement, the more extra credit. However, doing a good job investigating, explaining and justifying your work with small experiments and comments is also extremely important. Make sure to describe what you did and analyze why your method works. Use this ipython notebook to show your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def replace_punctuation(doc): #doc is a string\n",
    "    puncts='.,'#Want to remove comma and fullstop\n",
    "    for punct in puncts:\n",
    "        doc=doc.replace(punct,' ')\n",
    "    return doc\n",
    "    #Gave an accuracy of 81.84 \n",
    "    \n",
    "def tokenize_doc_and_more(doc):\n",
    "    \"\"\"\n",
    "    Return some representation of a document.\n",
    "    At a minimum, you need to perform tokenization, the rest is up to you.\n",
    "    \"\"\"\n",
    "    # Implement me!\n",
    "    bow = defaultdict(float)\n",
    "    doc = unicode(doc, 'utf-8')\n",
    "    doc=doc.lower()\n",
    "    #doc=replace_punctuation(doc)\n",
    "    # your code goes here\n",
    "    #wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens=word_tokenize(doc)\n",
    "    stop_words1=set(stopwords.words('english'))\n",
    "    word_tokens = [w for w in word_tokens if not w in stop_words1]\n",
    "    #word_tokens=[wordnet_lemmatizer.lemmatize(w) for w in word_tokens]\n",
    "    #word_tokens_2=[]\n",
    "    #for i in range(len(word_tokens)-1):\n",
    "    #    word_tokens_2.append(word_tokens[i]+\" \"+word_tokens[i+1])\n",
    "    #    i+=1\n",
    "    for token in word_tokens:\n",
    "        bow[token]+=1.0\n",
    "    #return dict(bow)\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORTING CORPUS STATISTICS\n",
      "NUMBER OF DOCUMENTS IN POSITIVE CLASS: 12500.0\n",
      "NUMBER OF DOCUMENTS IN NEGATIVE CLASS: 12500.0\n",
      "NUMBER OF TOKENS IN POSITIVE CLASS: 2156724.0\n",
      "NUMBER OF TOKENS IN NEGATIVE CLASS: 2116501.0\n",
      "VOCABULARY SIZE: NUMBER OF UNIQUE WORDTYPES IN TRAINING CORPUS: 114545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83.888"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = NaiveBayes(PATH_TO_DATA, tokenizer=tokenize_doc_and_more)\n",
    "nb.train_model()\n",
    "nb.evaluate_classifier_accuracy(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cells at the bottom of this notebook to explain what you did in `better_tokenize_doc`. Include any experiments or explanations that you used to decide what goes in your function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your experiments and explanations go here\n",
    "#Only nltk_tokenizer:\n",
    "#alpha: 3.1: 82.5\n",
    "#alpha:   1: 82.208\n",
    "#alpha:   2: 82.388\n",
    "#alpha:   4: 82.572\n",
    "#alpha:   5: 82.528\n",
    "\n",
    "#tokenizer & lemmatizer:\n",
    "#alpha: 1: 82.208\n",
    "#alpha: 2: 82.388\n",
    "#alpha: 3: 82.496\n",
    "#alpha: 4: 82.572\n",
    "#alpha: 5: 82.528\n",
    "\n",
    "#tokenizer and punctuation:\n",
    "#alpha: 3: 82.392\n",
    "#alpha: 4: 82.492\n",
    "#alpha: 5: 82.5\n",
    "\n",
    "#bigram (i,i+1) and tokenizer:\n",
    "#alpha 3: 82.936\n",
    "#alpha 4: 83.004\n",
    "#alpha 5: 82.932\n",
    "\n",
    "#stop and tokenize:\n",
    "#alpha: 3: 83.484\n",
    "#alpha: 4: 83.592\n",
    "#alpha: 5: 83.656\n",
    "#alpha: 7: 83.716\n",
    "#alpha: 8: 83.772\n",
    "#alpha: 9: 83.824\n",
    "#alpha: 10: 83.824\n",
    "#alpha: 11,12: 83.868\n",
    "#alpha: 13: 83.888\n",
    "#alpha: 14: 83.884"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
